{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0400fe7-1e50-481d-bb7e-62f2c126d4c2",
      "metadata": {
        "id": "f0400fe7-1e50-481d-bb7e-62f2c126d4c2"
      },
      "source": [
        "\n",
        "# Aufgabe 3 - Tiefe Einblicke ins Institut: Reloaded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e59687f3-c461-4f6e-a898-d023cdc8c67c",
      "metadata": {
        "id": "e59687f3-c461-4f6e-a898-d023cdc8c67c"
      },
      "source": [
        "Den Code immer nachvollziehbar kommentieren! Bitte beachtet, dass das Notebook von Anfang bis Ende ohne Fehler durchlaufen muss und dass die requirements.txt Datei aktualisiert wird."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "48e97f2a-c3df-4121-8b13-eb35a1e77435",
      "metadata": {
        "id": "48e97f2a-c3df-4121-8b13-eb35a1e77435",
        "ExecuteTime": {
          "end_time": "2023-07-24T20:17:08.201247Z",
          "start_time": "2023-07-24T20:17:06.837118Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh1-dSM38AkY",
        "outputId": "5c5484f6-72f9-4427-b89e-30ce3b316d9d",
        "ExecuteTime": {
          "end_time": "2023-07-24T20:17:08.211252Z",
          "start_time": "2023-07-24T20:17:08.202542Z"
        }
      },
      "id": "Mh1-dSM38AkY",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5f0020-55eb-4023-a883-90ac6206cfb3",
      "metadata": {
        "id": "ec5f0020-55eb-4023-a883-90ac6206cfb3"
      },
      "source": [
        "## Teilaufgabe a): Trainings-, Test-und Validierungsdatenset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "2c91f492-e05c-4a7f-9a1c-8674e2ed71d4",
      "metadata": {
        "id": "2c91f492-e05c-4a7f-9a1c-8674e2ed71d4"
      },
      "outputs": [],
      "source": [
        "training_list = []\n",
        "test_list = []\n",
        "validation_list = []\n",
        "\n",
        "name_to_label = {\n",
        "            'Professorenbuero': 0,\n",
        "            'Flur': 1,\n",
        "            'Labor': 2,\n",
        "            'Teekueche': 3\n",
        "        }\n",
        "\n",
        "for path_name in name_to_label.keys():\n",
        "    pic_amount = 25\n",
        "    tmp_paths = [(f\"/content/drive/MyDrive/Colab Notebooks/Bilder/{path_name}/{path_name + str(i + 1)}.jpg\", name_to_label[path_name] )for i in range(pic_amount)] #(Tensor,lbl) list\n",
        "    random.shuffle(tmp_paths)\n",
        "\n",
        "    training_list += tmp_paths[:int(0.7 * pic_amount)]\n",
        "    validation_list += tmp_paths[int(0.7 * pic_amount):int(0.8 * pic_amount)] # 3 pics each\n",
        "    test_list += tmp_paths[int(0.8 * pic_amount):]\n",
        "\n",
        "training_path_list, y_train = [tup[0] for tup in training_list], [tup[1] for tup in training_list]\n",
        "test_path_list, y_test = [tup[0] for tup in test_list], [tup[1] for tup in test_list]\n",
        "validation_path_list, y_val = [tup[0] for tup in validation_list], [tup[1] for tup in validation_list] # [\"./pfad/zu/bildZ.png\",\"./pfad/zu/bildY.png\",...], [1,1,1,2,2,2,...]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b16c6c68-033e-4d57-ba02-fc86c53f34f1",
      "metadata": {
        "id": "b16c6c68-033e-4d57-ba02-fc86c53f34f1"
      },
      "source": [
        "## Teilaufgabe b): CNN definieren und implementieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "3f484794-3ab2-4edf-84e4-8debf29b1d57",
      "metadata": {
        "id": "3f484794-3ab2-4edf-84e4-8debf29b1d57"
      },
      "outputs": [],
      "source": [
        "class NetComplex(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # cite\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        #self.fc1 = nn.Linear(43264, 256)\n",
        "        self.fc1 = nn.Linear(43264, 16)\n",
        "        #self.fc2 = nn.Linear(256, 16)\n",
        "        self.fc3 = nn.Linear(16, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #layer 1\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.bn1(x)\n",
        "        #layer 2\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.bn2(x)\n",
        "        # layer 3\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.bn3(x)\n",
        "        # flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "        # dense layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NetComplexP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # cite\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(18432, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 4)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #layer 1\n",
        "        x = self.dropout(self.pool(F.relu(self.conv1(x))))\n",
        "        #layer 2\n",
        "        x = self.dropout(self.pool(F.relu(self.conv2(x))))\n",
        "        # layer 3\n",
        "        x = self.dropout(self.pool(F.relu(self.conv3(x))))\n",
        "        # layer 4\n",
        "        x = self.dropout(self.pool(F.relu(self.conv4(x))))\n",
        "        # flatten\n",
        "        x = torch.flatten(x, 1)\n",
        "        # dense layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ymBj1W3-hC_y"
      },
      "id": "ymBj1W3-hC_y",
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(3, 16, 4)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Calculate the correct input size for the FC layer\n",
        "        self.fc1 = nn.Linear(16 * 110 * 110, 1550)\n",
        "        self.fc2 = nn.Linear(1550, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "87Ia4lH6YuR6"
      },
      "id": "87Ia4lH6YuR6"
    },
    {
      "cell_type": "markdown",
      "id": "2bb17fba-193f-4873-a631-7a902bb54675",
      "metadata": {
        "tags": [],
        "id": "2bb17fba-193f-4873-a631-7a902bb54675"
      },
      "source": [
        "## Teilaufgabe c): Training und Test mit CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1369c7d9-bb8e-4856-943e-317067000bb7",
      "metadata": {
        "id": "1369c7d9-bb8e-4856-943e-317067000bb7"
      },
      "source": [
        "Datenset-Klasse um mit Pytorch Bilder zu laden.\n",
        "\n",
        "Input sind:\n",
        "- Liste mit Pfaden zu Bildern\n",
        "- Liste mit dazugeh√∂rigen Labels (numerisch darstellen!)\n",
        "- Transformation der Bilder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "c3b2967c-06da-4bda-a6a6-a0994d92bdc6",
      "metadata": {
        "id": "c3b2967c-06da-4bda-a6a6-a0994d92bdc6"
      },
      "outputs": [],
      "source": [
        "class ROBDataset(Dataset):\n",
        "    def __init__(self, img_path_list, img_labels, transform=None):\n",
        "        # Pfade zu den Bildern als list\n",
        "        self.img_path_list = img_path_list\n",
        "\n",
        "        # Dazugeh√∂rige Labels zu den Bildern als list\n",
        "        self.img_labels = img_labels\n",
        "\n",
        "        # Transformations der Bilder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Bild laden\n",
        "        img_path = self.img_path_list[idx]\n",
        "        image = read_image(img_path)\n",
        "\n",
        "        # Label laden\n",
        "        label = self.img_labels[idx]\n",
        "\n",
        "        # Transformieren\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image.float(), int(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb8928b-daf3-459e-a540-aa98944b18e3",
      "metadata": {
        "id": "fdb8928b-daf3-459e-a540-aa98944b18e3"
      },
      "source": [
        "Trainingsiteration √ºber alle Bilder.\n",
        "\n",
        "Inputs sind:\n",
        "- Pytorch dataloader Object √ºber das iteriert wird\n",
        "- bool do_backprob Parameter um Backpropagation durchzuf√ºhren oder nicht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "aaaff24b-78a7-4701-915d-0e271402f70a",
      "metadata": {
        "id": "aaaff24b-78a7-4701-915d-0e271402f70a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Iterating over the entire data set once\n",
        "def run_iteration(dataloader, do_backprob=True):\n",
        "    global net, optimizer, criterion\n",
        "    loss_iter = []\n",
        "    acc_iter = []\n",
        "    for batch_x, batch_y in dataloader:\n",
        "        # To device\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        y_predict = net(batch_x)\n",
        "        loss = criterion(y_predict, batch_y)\n",
        "        if do_backprob:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        loss_iter.append(loss.detach().cpu().numpy())\n",
        "\n",
        "        _, predicted = torch.max(torch.softmax(y_predict, dim=1),1)\n",
        "\n",
        "        acc_iter.append(accuracy_score(batch_y.detach().cpu().numpy(),\n",
        "                                       predicted.detach().cpu().numpy()))\n",
        "\n",
        "    return np.mean(loss_iter), np.mean(acc_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e616ae6-75e5-42a1-be39-d914424fe62d",
      "metadata": {
        "id": "0e616ae6-75e5-42a1-be39-d914424fe62d"
      },
      "source": [
        "Komplette Durchf√ºhrung eines Trainings\n",
        "Die Variablen y_train, y_val und y_test m√ºssen noch gesetzt werden. Diese Listen beinhalten die entsprechenden Labels als numerische Darstellung."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "094c918f-85f4-48b5-a089-4215da53b075",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "094c918f-85f4-48b5-a089-4215da53b075",
        "outputId": "cd4cac34-f21d-40d8-be18-bd5847d617cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on  cuda:0\n",
            "\n",
            "Started Training\n",
            "Epoch 1 from 100\n",
            "\tTrain Loss\t 1.2976581\n",
            "\tTrain Acc.\t 0.5\n",
            "\tVal Loss\t 1.476952\n",
            "\tVal Acc.\t 0.25\n",
            "Epoch 2 from 100\n",
            "\tTrain Loss\t 0.118442394\n",
            "\tTrain Acc.\t 0.9375\n",
            "\tVal Loss\t 1.5228052\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 3 from 100\n",
            "\tTrain Loss\t 0.09415746\n",
            "\tTrain Acc.\t 0.925\n",
            "\tVal Loss\t 1.589326\n",
            "\tVal Acc.\t 0.4166666666666667\n",
            "Epoch 4 from 100\n",
            "\tTrain Loss\t 0.0050720572\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 1.7302736\n",
            "\tVal Acc.\t 0.3333333333333333\n",
            "Epoch 5 from 100\n",
            "\tTrain Loss\t 0.022488583\n",
            "\tTrain Acc.\t 0.9875\n",
            "\tVal Loss\t 2.0745394\n",
            "\tVal Acc.\t 0.25\n",
            "Epoch 6 from 100\n",
            "\tTrain Loss\t 0.00260652\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.418316\n",
            "\tVal Acc.\t 0.16666666666666666\n",
            "Epoch 7 from 100\n",
            "\tTrain Loss\t 0.03468284\n",
            "\tTrain Acc.\t 0.9875\n",
            "\tVal Loss\t 2.5442297\n",
            "\tVal Acc.\t 0.3333333333333333\n",
            "Epoch 8 from 100\n",
            "\tTrain Loss\t 0.005469193\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.4797745\n",
            "\tVal Acc.\t 0.3333333333333333\n",
            "Epoch 9 from 100\n",
            "\tTrain Loss\t 0.0020472752\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.209303\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 10 from 100\n",
            "\tTrain Loss\t 0.0030700788\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.1560624\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 11 from 100\n",
            "\tTrain Loss\t 0.00074989116\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.0131392\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 12 from 100\n",
            "\tTrain Loss\t 0.00047431994\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 1.8048072\n",
            "\tVal Acc.\t 0.4166666666666667\n",
            "Epoch 13 from 100\n",
            "\tTrain Loss\t 0.0005461464\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 1.9318537\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 14 from 100\n",
            "\tTrain Loss\t 0.00018105302\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 1.9802436\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 15 from 100\n",
            "\tTrain Loss\t 0.00018785929\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.006951\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 16 from 100\n",
            "\tTrain Loss\t 0.000108370754\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.0055819\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 17 from 100\n",
            "\tTrain Loss\t 0.00015246862\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.0426254\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 18 from 100\n",
            "\tTrain Loss\t 0.000101286976\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.2033184\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 19 from 100\n",
            "\tTrain Loss\t 0.00015960996\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.4157412\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 20 from 100\n",
            "\tTrain Loss\t 6.453567e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.4597034\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 21 from 100\n",
            "\tTrain Loss\t 0.00010689928\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.2948616\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 22 from 100\n",
            "\tTrain Loss\t 8.4547675e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.2951498\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 23 from 100\n",
            "\tTrain Loss\t 6.772551e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.1937332\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 24 from 100\n",
            "\tTrain Loss\t 8.943163e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.374029\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 25 from 100\n",
            "\tTrain Loss\t 0.00013438801\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.5026615\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 26 from 100\n",
            "\tTrain Loss\t 0.0012933222\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.3306386\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 27 from 100\n",
            "\tTrain Loss\t 0.00015405935\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.4586682\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 28 from 100\n",
            "\tTrain Loss\t 3.940045e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.3990538\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 29 from 100\n",
            "\tTrain Loss\t 8.444543e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.420253\n",
            "\tVal Acc.\t 0.5833333333333334\n",
            "Epoch 30 from 100\n",
            "\tTrain Loss\t 5.209063e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.7122357\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 31 from 100\n",
            "\tTrain Loss\t 5.2882813e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.6489842\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 32 from 100\n",
            "\tTrain Loss\t 0.00012099972\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.6548924\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 33 from 100\n",
            "\tTrain Loss\t 9.197226e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.7133825\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 34 from 100\n",
            "\tTrain Loss\t 2.617564e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.7682962\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 35 from 100\n",
            "\tTrain Loss\t 3.5678822e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.6329257\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 36 from 100\n",
            "\tTrain Loss\t 4.049326e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.6630707\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 37 from 100\n",
            "\tTrain Loss\t 8.075292e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.7074406\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 38 from 100\n",
            "\tTrain Loss\t 4.7730657e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.736786\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 39 from 100\n",
            "\tTrain Loss\t 8.130175e-05\n",
            "\tTrain Acc.\t 1.0\n",
            "\tVal Loss\t 2.7714736\n",
            "\tVal Acc.\t 0.5\n",
            "Epoch 40 from 100\n",
            "\tTrain Loss\t 4.307612e-05\n",
            "\tTrain Acc.\t 1.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-ec721557499b>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No gradient calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mval_loss_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_backprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Logging loss and accuarcy of validation iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-326ced86d9ee>\u001b[0m in \u001b[0;36mrun_iteration\u001b[0;34m(dataloader, do_backprob)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_backprob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-56ef3b6495eb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# dense layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m#x = F.relu(self.fc2(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training settings - bei Bedarf anpassbar\n",
        "max_epoch = 100\n",
        "batch_size = 16\n",
        "lr = 0.001\n",
        "\n",
        "# Transformations for dataloader\n",
        "t_train = T.Compose([T.ToPILImage(),\n",
        "                   T.ToTensor(),\n",
        "                   T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "t_val = T.Compose([T.ToPILImage(),\n",
        "                   T.ToTensor(),\n",
        "                   T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "t_test = T.Compose([T.ToPILImage(),\n",
        "                   T.ToTensor(),\n",
        "                   T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "\n",
        "# Where to do calculations\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on \",device)\n",
        "\n",
        "# Training Data, NOTE: y_train labels need to be set\n",
        "dataset_train = ROBDataset(training_path_list, y_train, transform=t_train)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Validation Data, NOTE: y_val labels need to be set\n",
        "dataset_val = ROBDataset(validation_path_list, y_val, transform=t_val)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Test Data, NOTE: y_test labels need. to be set\n",
        "dataset_test = ROBDataset(test_path_list, y_test,transform=t_test)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Network, optimizer and loss initialisation\n",
        "net = Net()\n",
        "net.to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Los geht's mit Training\n",
        "print(\"\\nStarted Training\")\n",
        "# Training loss and accuracy per epoch\n",
        "train_loss_epoch = []\n",
        "train_acc_epoch = []\n",
        "# Validation loss and accuracy per epoch\n",
        "val_loss_epoch = []\n",
        "val_acc_epoch = []\n",
        "\n",
        "for epoch in range(0,max_epoch):  # loop over the dataset multiple times\n",
        "    print(f\"Epoch {epoch+1} from {max_epoch}\")\n",
        "\n",
        "    ### TRAINING ###\n",
        "    net.train()\n",
        "    train_loss_iter, train_acc_iter = run_iteration(dataloader_train)\n",
        "\n",
        "    # Logging loss and accuarcy of training iteration\n",
        "    train_loss_epoch.append(train_loss_iter)\n",
        "    train_acc_epoch.append(train_acc_iter)\n",
        "    print(\"\\tTrain Loss\\t\",train_loss_iter)\n",
        "    print(\"\\tTrain Acc.\\t\",train_acc_iter)\n",
        "\n",
        "    ### VALIDATION ###\n",
        "    with torch.no_grad():  # No gradient calculation\n",
        "        net.eval()\n",
        "        val_loss_iter, val_acc_iter = run_iteration(dataloader_val,do_backprob=False)\n",
        "\n",
        "        # Logging loss and accuarcy of validation iteration\n",
        "        val_loss_epoch.append(val_loss_iter)\n",
        "        val_acc_epoch.append(val_acc_iter)\n",
        "        print(\"\\tVal Loss\\t\",val_loss_iter)\n",
        "        print(\"\\tVal Acc.\\t\",val_acc_iter)\n",
        "\n",
        "# Plotting results\n",
        "fig, ax = plt.subplots(nrows=1,ncols=2,figsize=(10,3))\n",
        "ax[0].plot(train_loss_epoch,label=\"Train\")\n",
        "ax[0].plot(val_loss_epoch,label=\"Val\",linestyle=\"-.\")\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(train_acc_epoch,label=\"Train\")\n",
        "ax[1].plot(val_acc_epoch,label=\"Val\",linestyle=\"-.\")\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].legend()\n",
        "plt.savefig(\"loss_augmentation.png\",format=\"png\",bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjFB5XoQj9NW"
      },
      "id": "JjFB5XoQj9NW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9NdlvqGiFPy"
      },
      "id": "X9NdlvqGiFPy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_Z1JSv2ZcrO"
      },
      "id": "Z_Z1JSv2ZcrO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "823af297-bb62-4e02-a376-99fc47618b08",
      "metadata": {
        "id": "823af297-bb62-4e02-a376-99fc47618b08"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "51e14a88-cf54-40a0-b118-05e243e0b995",
      "metadata": {
        "tags": [],
        "id": "51e14a88-cf54-40a0-b118-05e243e0b995"
      },
      "source": [
        "## Teilaufgabe d): Augmentierung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65263759-2c02-43f0-b756-c8f8ad77b75e",
      "metadata": {
        "id": "65263759-2c02-43f0-b756-c8f8ad77b75e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ba0cffb4-b4dd-4df8-b7d5-f2f98c8a698b",
      "metadata": {
        "tags": [],
        "id": "ba0cffb4-b4dd-4df8-b7d5-f2f98c8a698b"
      },
      "source": [
        "## Teilaufgabe e): Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a72c1da-07de-4252-a4a9-b373918b1cf2",
      "metadata": {
        "tags": [],
        "id": "4a72c1da-07de-4252-a4a9-b373918b1cf2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
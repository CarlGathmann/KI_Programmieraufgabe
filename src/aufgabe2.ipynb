{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0400fe7-1e50-481d-bb7e-62f2c126d4c2",
   "metadata": {},
   "source": [
    "# Aufgabe 2 - Tiefe Einblicke ins Institut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59687f3-c461-4f6e-a898-d023cdc8c67c",
   "metadata": {},
   "source": [
    "Den Code immer nachvollziehbar kommentieren! Bitte beachtet, dass das Notebook von Anfang bis Ende ohne Fehler durchlaufen muss und dass die requirements.txt Datei aktualisiert wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f0020-55eb-4023-a883-90ac6206cfb3",
   "metadata": {},
   "source": [
    "## Teilaufgabe a): Trainings-und Testdatenset\n",
    "## Teilaufgabe b): Verteilung RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c91f492-e05c-4a7f-9a1c-8674e2ed71d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-05T13:57:59.652755Z",
     "start_time": "2023-07-05T13:57:59.556856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "5\n",
      "(array([144, 158, 188, 343, 395, 496, 438, 442, 434, 411, 400, 325, 313,\n",
      "       254, 252, 217, 175, 174, 144, 108, 127, 141, 149, 145, 146, 161,\n",
      "       159, 168, 142, 159, 196, 194, 238, 258, 226, 200, 218, 217, 221,\n",
      "       203, 212, 226, 242, 286, 258, 270, 271, 254, 250, 228, 230, 220,\n",
      "       135, 153, 142, 126, 142, 130, 142, 151, 161, 145, 160, 193, 174,\n",
      "       184, 195, 216, 229, 192, 239, 206, 232, 205, 186, 225, 189, 215,\n",
      "       180, 214, 207, 229, 191, 242, 276, 321, 339, 351, 352, 271, 286,\n",
      "       258, 263, 272, 222, 246, 213, 226, 251, 240, 231, 237, 219, 216,\n",
      "       198, 205, 206, 195, 215, 231, 259, 298, 296, 302, 364, 413, 474,\n",
      "       468, 527, 553, 467, 411, 387, 358, 328, 315, 313, 282, 312, 292,\n",
      "       313, 400, 360, 367, 359, 291, 290, 342, 332, 343, 357, 344, 291,\n",
      "       297, 259, 262, 244, 250, 248, 237, 274, 259, 276, 277, 233, 230,\n",
      "       214, 243, 239, 215, 228, 265, 243, 226, 193, 188, 215, 206, 210,\n",
      "       195, 203, 190, 198, 182, 190, 163, 190, 184, 195, 180, 187, 142,\n",
      "       141, 103,  80,  96, 103,  98,  93,  86,  70,  66,  70,  79,  81,\n",
      "        81,  63,  94,  83,  84,  78,  72, 100,  76,  68,  79,  68,  76,\n",
      "        68,  65,  66,  72,  70,  72,  74,  84,  78,  75,  67,  81,  82,\n",
      "        77,  67,  72,  72,  66,  54,  68,  56,  63,  48,  48,  43,  42,\n",
      "        56,  44,  39,  55,  45,  37,  60,  41,  39,  37,  37,  33,  30,\n",
      "        38,  37,  28,  29,  31,  53,  22,  69,  64, 313, 119, 148, 170,\n",
      "       264, 438, 499, 524, 519, 462, 417, 362, 335, 314, 263, 252, 211,\n",
      "       187, 138, 153, 169, 155, 180, 204, 215, 181, 160, 151, 168, 182,\n",
      "       226, 272, 256, 263, 259, 250, 238, 272, 292, 305, 322, 367, 381,\n",
      "       394, 386, 318, 316, 311, 284, 248, 236, 192, 157, 164, 152, 167,\n",
      "       172, 182, 174, 182, 164, 177, 177, 172, 185, 157, 164, 159, 168,\n",
      "       152, 162, 176, 179, 181, 179, 182, 184, 193, 201, 199, 246, 248,\n",
      "       272, 255, 270, 248, 242, 219, 239, 227, 233, 234, 194, 233, 214,\n",
      "       210, 225, 198, 194, 175, 161, 159, 191, 200, 232, 211, 234, 232,\n",
      "       301, 349, 338, 422, 461, 539, 496, 454, 454, 349, 364, 373, 347,\n",
      "       298, 280, 269, 246, 300, 303, 339, 292, 354, 324, 310, 325, 276,\n",
      "       284, 278, 358, 359, 302, 300, 277, 257, 263, 246, 257, 226, 239,\n",
      "       257, 227, 264, 249, 297, 263, 239, 211, 193, 260, 237, 214, 245,\n",
      "       260, 231, 247, 220, 215, 195, 215, 205, 167, 173, 186, 194, 161,\n",
      "       180, 168, 160, 159, 145, 118, 109,  85,  81,  71,  74,  56,  46,\n",
      "        60,  50,  36,  62,  54,  53,  68,  62,  64,  67,  81,  55,  68,\n",
      "        76,  72,  76,  69,  74,  72,  58,  63,  73,  72,  73,  79,  70,\n",
      "        78,  73,  65,  87,  69,  74,  71,  80,  81,  72,  60,  77,  66,\n",
      "        65,  73,  78,  62,  63,  68,  46,  65,  53,  50,  57,  53,  56,\n",
      "        61,  50,  69,  59,  54,  78,  60,  52,  53,  53,  59,  60,  50,\n",
      "        69,  57,  84,  84, 291, 490, 133, 213, 326, 428, 425, 406, 438,\n",
      "       405, 327, 320, 335, 312, 286, 232, 220, 206, 218, 190, 230, 223,\n",
      "       226, 238, 247, 327, 353, 352, 414, 428, 472, 440, 422, 349, 406,\n",
      "       456, 496, 439, 283, 242, 208, 175, 203, 192, 194, 178, 185, 193,\n",
      "       186, 182, 195, 180, 176, 195, 194, 165, 188, 146, 161, 165, 171,\n",
      "       175, 200, 165, 178, 211, 199, 252, 233, 237, 254, 244, 244, 264,\n",
      "       219, 236, 261, 228, 246, 251, 242, 247, 230, 232, 207, 207, 175,\n",
      "       160, 151, 160, 184, 161, 152, 154, 188, 233, 258, 281, 403, 442,\n",
      "       442, 445, 465, 356, 410, 410, 305, 289, 275, 261, 257, 268, 291,\n",
      "       251, 319, 334, 336, 355, 332, 314, 291, 277, 260, 241, 283, 293,\n",
      "       279, 288, 278, 229, 288, 255, 246, 230, 236, 250, 242, 223, 249,\n",
      "       242, 251, 281, 280, 285, 254, 269, 286, 266, 290, 247, 297, 247,\n",
      "       237, 234, 268, 292, 250, 233, 270, 260, 246, 243, 243, 230, 247,\n",
      "       242, 242, 211, 227, 239, 235, 213, 218, 216, 178, 159, 149, 135,\n",
      "       107,  94,  87,  92,  82,  98,  79,  82,  77,  63,  83,  70,  76,\n",
      "        69,  75,  76,  66,  67,  71,  64,  70,  57,  64,  62,  52,  59,\n",
      "        65,  50,  41,  44,  48,  53,  47,  50,  31,  33,  39,  34,  24,\n",
      "        28,  34,  28,  33,  32,  37,  31,  17,  29,  23,  18,  27,  32,\n",
      "        27,  26,  19,  26,  20,  21,  21,  16,  19,  21,  29,  32,  22,\n",
      "        28,  33,  25,  21,  18,  20,  29,  26,  29,  25,  12,  30,  14,\n",
      "        83]), 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\nfig, ax = plt.subplots(2, 2, figsize=(10, 10))\\nax[0, 0].hist(prof_pics.histogram, label='prof', bins=768)\\nax[0, 1].hist(hall_pics.histogram, label='hall', bins=768)\\nax[1, 0].hist(lab_pics.histogram, label='lab', bins=768)\\nax[1, 1].hist(tea_pics.histogram, label='tea', bins=768)\\n\\nax[0, 0].legend()\\nax[0, 1].legend()\\nax[1, 0].legend()\\nax[1, 1].legend()\\n\\nplt.show()\\n\""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def thumbnail(img):\n",
    "    img_list = np.asarray(img.resize((30, 30))).reshape(1, 2700)\n",
    "    final_list = np.array([item for sublist in img_list for item in sublist])\n",
    "    return final_list\n",
    "\n",
    "\n",
    "class PicData:\n",
    "    def __init__(self, name):\n",
    "        file_paths = {\n",
    "            'prof': \"Professorenbuero\",\n",
    "            'hall': \"Flur\",\n",
    "            'lab': \"Labor\",\n",
    "            'tea': \"Teekueche\"\n",
    "        }\n",
    "        name_to_label = {\n",
    "            'prof': 1,\n",
    "            'hall': 2,\n",
    "            'lab': 3,\n",
    "            'tea': 4\n",
    "        }\n",
    "        pic_amount = len(os.listdir(f\"Bilder/{file_paths[name]}\"))\n",
    "        self.path = file_paths[name]\n",
    "        self.pics = [Image.open(f\"Bilder/{self.path}/{self.path + str(i + 1)}.jpg\") for i in range(pic_amount)]\n",
    "        self.data = np.array([img.histogram() for img in self.pics])\n",
    "        random.shuffle(self.data)\n",
    "        #self.labels = np.array([name_to_label[name] for _ in range(len(self.data))])\n",
    "        #self.img_train, self.img_test, self.lbl_train, self.lbl_test = train_test_split(self.data, self.labels, test_size=0.2)\n",
    "        self.train = [(self.data[i], name_to_label[name]) for i in range(int(0.8 * len(self.data)))]\n",
    "        self.test  = [(self.data[i], name_to_label[name]) for i in range(int(0.8 * len(self.data)), len(self.data))]\n",
    "\n",
    "prof_pics = PicData('prof')\n",
    "hall_pics = PicData('hall')\n",
    "lab_pics = PicData('lab')\n",
    "tea_pics = PicData('tea')\n",
    "\n",
    "'''print(len(prof_pics.train))\n",
    "print(len(prof_pics.test))\n",
    "print(prof_pics.train[0])\n",
    "print(prof_pics.img_test)\n",
    "print(prof_pics.lbl_train)\n",
    "print(prof_pics.lbl_test)\n",
    "'''\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0, 0].hist(prof_pics.histogram, label='prof', bins=768)\n",
    "ax[0, 1].hist(hall_pics.histogram, label='hall', bins=768)\n",
    "ax[1, 0].hist(lab_pics.histogram, label='lab', bins=768)\n",
    "ax[1, 1].hist(tea_pics.histogram, label='tea', bins=768)\n",
    "\n",
    "ax[0, 0].legend()\n",
    "ax[0, 1].legend()\n",
    "ax[1, 0].legend()\n",
    "ax[1, 1].legend()\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb17fba-193f-4873-a631-7a902bb54675",
   "metadata": {},
   "source": [
    "## Teilaufgabe c): Training und Test mit Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "'complete_image_list = list(prof_pics.img_train) + list(hall_pics.img_train) + list(lab_pics.img_train) + list(tea_pics.img_train)\\ncomplete_label_list = list(prof_pics.lbl_train) + list(hall_pics.lbl_train) + list(lab_pics.lbl_train) + list(tea_pics.lbl_train)\\nrf.fit(complete_image_list, complete_label_list)'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "complete_train = list(prof_pics.train) + list(hall_pics.train) + list(lab_pics.train) + list(tea_pics.train)\n",
    "complete_test = list(prof_pics.test) + list(hall_pics.test) + list(lab_pics.test) + list(tea_pics.test)\n",
    "random.shuffle(complete_train)\n",
    "random.shuffle(complete_test)\n",
    "\n",
    "\n",
    "X_train = [item[0] for item in complete_train]\n",
    "y_train = [item[1] for item in complete_train]\n",
    "X_test = [item[0] for item in complete_test]\n",
    "y_test = [item[1] for item in complete_test]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = rf.predict(X_train)\n",
    "print(r2_score(y_train, y_pred_train))\n",
    "\n",
    "'''complete_image_list = list(prof_pics.img_train) + list(hall_pics.img_train) + list(lab_pics.img_train) + list(tea_pics.img_train)\n",
    "complete_label_list = list(prof_pics.lbl_train) + list(hall_pics.lbl_train) + list(lab_pics.lbl_train) + list(tea_pics.lbl_train)\n",
    "rf.fit(complete_image_list, complete_label_list)'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T13:40:59.714655Z",
     "start_time": "2023-07-05T13:40:59.702663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 1 1 1 4 2 4 1 1 4 3 2 3 2 3 4 3 3 2]\n",
      "[2, 3, 4, 1, 1, 4, 1, 2, 1, 1, 4, 4, 2, 3, 2, 3, 4, 3, 3, 2]\n",
      "0.4\n",
      "Mean Absolute Error: 0.35°.\n",
      "Score: 0.8\n",
      "Accuracy: 85.0 %.\n"
     ]
    }
   ],
   "source": [
    "current_test_list = complete_test\n",
    "current_test_data = [item[0] for item in current_test_list]\n",
    "current_test_lbl = [item[1] for item in current_test_list]\n",
    "\n",
    "y_pred = rf.predict(current_test_data)\n",
    "print(y_pred)\n",
    "print(current_test_lbl)\n",
    "\n",
    "print(r2_score(current_test_lbl, y_pred))\n",
    "\n",
    "\n",
    "errors = abs(y_pred - current_test_lbl)\n",
    "print('Mean Absolute Error:', str(round(np.mean(errors), 2)) + '°.')\n",
    "\n",
    "print(\"Score:\", rf.score(current_test_data, current_test_lbl))\n",
    "\n",
    "mape = 100 * (errors / current_test_lbl)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T13:41:23.931547Z",
     "start_time": "2023-07-05T13:41:23.928766Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "51e14a88-cf54-40a0-b118-05e243e0b995",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teilaufgabe d): Hyperparameteroptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65263759-2c02-43f0-b756-c8f8ad77b75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0cffb4-b4dd-4df8-b7d5-f2f98c8a698b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teilaufgabe e): Dimensionalitätsreduktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72c1da-07de-4252-a4a9-b373918b1cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
